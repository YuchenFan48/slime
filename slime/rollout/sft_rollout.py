from transformers import AutoTokenizer
from argparse import Namespace
from slime.utils.mask_utils import MultiTurnLossMaskGenerator
from typing import Any, Callable, Union
from slime.utils.data import Dataset
import copy
from slime.utils.types import Sample

__all__ = ["generate_rollout"]


TOKENIZER = None
MASK_GENERATOR = None
EVAL_PROMPT_DATASET = {}
EVAL_PROCESSED_SAMPLES = {}  # 新增：缓存已处理的样本

def eval_rollout(args: Namespace, rollout_id: int) -> tuple[dict[str, dict[str, list[Any]]], list[list[Sample]]]:
    # 初始化全局变量（如果尚未初始化）
    global TOKENIZER, MASK_GENERATOR
    if TOKENIZER is None:
        TOKENIZER = AutoTokenizer.from_pretrained(args.hf_checkpoint, trust_remote_code=True)
    if MASK_GENERATOR is None:
        MASK_GENERATOR = MultiTurnLossMaskGenerator(TOKENIZER, tokenizer_type=args.loss_mask_type)
    
    results = {}
    for i in range(0, len(args.eval_prompt_data), 2):
        name, path = args.eval_prompt_data[i : i + 2]
        print(f"loading {name}...")
        results.update(eval_rollout_single_dataset(args, rollout_id, name, path))
    return results, []

def eval_rollout_single_dataset(
    args: Namespace, rollout_id: int, name: str, path: str
) -> dict[str, dict[str, list[Any]]]:
    """An example to implement the eval_rollout function for an rule based rm rollout generation.

    Args:
        args: the whole args
        rollout_id: int, the id of the rollout, used for deterministic data generation
        name: str, the name of the dataset
        path: str, the path of the dataset
    """
    global EVAL_PROMPT_DATASET, EVAL_PROCESSED_SAMPLES
    
    # 检查是否已经加载并处理过这个数据集
    if name in EVAL_PROCESSED_SAMPLES:
        print(f"Using cached processed samples for {name}")
        return {name: EVAL_PROCESSED_SAMPLES[name]}
    
    # 加载数据集（如果尚未加载）
    if name not in EVAL_PROMPT_DATASET:
        print(f"Loading dataset {name} from {path}")
        tokenizer = TOKENIZER  # 使用全局初始化的tokenizer
        EVAL_PROMPT_DATASET[name] = Dataset(
            path,
            tokenizer=tokenizer,
            max_length=args.rollout_max_prompt_len,
            prompt_key=args.input_key if args.eval_input_key is None else args.eval_input_key,
            label_key=args.label_key if args.eval_label_key is None else args.eval_label_key,
            multimodal_keys=args.multimodal_keys,
            metadata_key=args.metadata_key,
            tool_key=args.tool_key if args.eval_tool_key is None else args.eval_tool_key,
            apply_chat_template=args.apply_chat_template,
        )
    
    dataset = EVAL_PROMPT_DATASET[name]
    
    samples = []
    prompt_samples = dataset.samples
    sample_index = 0
    for prompt_sample in prompt_samples:
        group = []
        for _ in range(args.n_samples_per_prompt):
            sample = copy.deepcopy(prompt_sample)
            sample.index = sample_index
            sample_index += 1
            group.append(sample)
        samples.append(group)

    for sample in samples:
        (sample,) = sample
        messages = sample.prompt
        token_ids, loss_mask = MASK_GENERATOR.get_loss_mask(messages)
        response_length = MASK_GENERATOR.get_response_lengths([loss_mask])[0]

        sample.tokens = token_ids
        sample.response_length = response_length
        sample.reward = 0
        sample.loss_mask = loss_mask[-response_length:]
    
    # 展平样本列表
    while isinstance(samples[0], list):
        samples = sum(samples, [])
    
    # 调整样本数量以匹配批次大小
    if len(samples) % args.global_batch_size != 0:
        trim_len = (len(samples) // args.global_batch_size) * args.global_batch_size
        origin_data_length = len(samples)
        samples = samples[:trim_len]
        print(f"trim number of samples from {origin_data_length} to {trim_len}")
    
    # 缓存处理后的样本
    EVAL_PROCESSED_SAMPLES[name] = samples
    
    return {name: samples}

def generate_rollout(args, rollout_id, data_buffer, evaluation=False):
    """An example to implement the generate_rollout function for an rule based rm rollout generation.

    Args:
        args: the whole args
        rollout_id: int, the id of the rollout, used for deterministic data generation
        data_buffer: the data buffer to store the generated samples
        evaluation: bool, whether the rollout is for evaluation or not

    Returns:
        list[Sample]: a list of samples generated by the rollout
    """
    # assert not evaluation
    assert args.rollout_global_dataset

    if evaluation:
        return eval_rollout(args, rollout_id)
    
    global TOKENIZER, MASK_GENERATOR
    if TOKENIZER is None:
        TOKENIZER = AutoTokenizer.from_pretrained(args.hf_checkpoint, trust_remote_code=True)

    if MASK_GENERATOR is None:
        MASK_GENERATOR = MultiTurnLossMaskGenerator(TOKENIZER, tokenizer_type=args.loss_mask_type)

    samples = data_buffer.get_samples(args.rollout_batch_size)

    for sample in samples:
        (sample,) = sample
        messages = sample.prompt
        token_ids, loss_mask = MASK_GENERATOR.get_loss_mask(messages)
        response_length = MASK_GENERATOR.get_response_lengths([loss_mask])[0]

        sample.tokens = token_ids
        sample.response_length = response_length
        sample.reward = 0
        sample.loss_mask = loss_mask[-response_length:]
    return samples
